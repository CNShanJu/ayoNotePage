>官网：https://hadoop.apache.org/
>中文文档：https://hadoop.org.cn/

## hadoop是什么

`Hadoop`是由`java`语言编写的，在分布式服务器集群上存储海量数据并运行分布式分析应用的开源框架，其核心部件是`HDFS`与`MapReduce`。

`HDFS`是一个***分布式文件系统***：引入存放文件元数据信息的服务器Namenode和实际存放数据的服务器Datanode，对数据进行分布式储存和读取。

`MapReduce`是一个***分布式计算框架***：MapReduce的核心思想是把计算任务分配给集群内的服务器里执行。通过对计算任务的拆分（Map计算/Reduce计算）再根据任务调度器（JobTracker）对任务进行分布式计算。

> (1)Hadoop是一个开源的框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。Hadoop=HDFS（文件系统，数据存储技术相关）+ Mapreduce（数据处理），Hadoop的数据来源可以是任何形式，在处理`半结构化`和`非结构化`数据上与关系型数据库相比有更好的性能，具有更灵活的处理能力，不管任何数据形式最终会转化为`key/value`，key/value是`基本数据单元`。用函数式变成Mapreduce代替SQL，SQL是查询语句，而Mapreduce则是使用脚本和代码，而对于适用于关系型数据库，习惯`SQL`的Hadoop有开源工具`hive`代替。
>
> (2)[Hadoop](http://lib.csdn.net/base/hadoop)就是一个分布式计算的解决方案.

#### **记住下面的话：**

 `Hadoop`的框架最核心的设计就是：`HDFS`和`MapReduce`。`HDFS`为海量的数据提供了`存储`，则`MapReduce`为海量的数据提供了`计算`。

把`HDFS`理解为一个分布式的，有冗余备份的，可以动态扩展的用来存储大规模数据的大硬盘。

把`MapReduce`理解成为一个计算引擎，按照`MapReduce`的规则编写`Map计算/Reduce计算`的程序，可以完成计算任务。

## Hadoop的发展历史

Hadoop是由Apache的Lucence项目创始人道格·卡廷创建的，Lucence是一个应用广泛的文本搜索系统库。Hadoop起源于开源的网络搜索引擎Nutch，Nutch本身也是Lucence项目的一部分。Hadoop的发展历史如图1所示。

![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/v2-78e4573ec2e865ecbbec9026c1f352e2_1440w.jpg)

## Hadoop的特点

Hadoop是一个能够让用户轻松搭建和使用的分布式计算平台，能够让用户轻松地在Hadoop上开发和运行处理海量数据的应用程序。Hadoop的主要特点如下。

**1）高可靠性。**Hadoop的数据存储有多个备份，集群部署在不同机器上，可以防止一个节点宕机造成集群损坏。当数据处理请求失败时，Hadoop将自动重新部署计算任务。

**2）高扩展性。**Hadoop是在可用的计算机集群间分配数据并完成计算任务的。为集群添加新的节点并不复杂，因此可以很容易地对集群进行节点的扩展。

**3）高效性。**Hadoop可以在节点之间动态地移动数据，在数据所在节点进行并行处理，并保证各个节点的动态平衡，因此处理速度非常快。

**4）高容错性。**Hadoop的分布式文件系统HDFS在存储文件时将在多台机器或多个节点上存储文件的备份副本，当读取该文件出错或某一台机器宕机时，系统会调用其他节点上的备份文件，保证程序顺利运行。

**5）低成本。**Hadoop是开源的，即不需要支付任何费用即可下载并安装使用，节省了购买软件的成本。

**6）可构建在廉价机器上。**Hadoop不要求机器的配置达到极高的标准，大部分普通商用服务器即可满足要求，通过提供多个副本和容错机制提高集群的可靠性。

**7）Hadoop基本框架是基于Java语言编写的。**Hadoop是一个基于Java语言开发的框架，因此运行在Linux系统上是非常理想的。Hadoop上的应用程序也可以使用其他语言编写，如C++和Python。

## **Hadoop存储框架—`HDFS`**

HDFS是一种旨在普通硬件上运行的分布式文件系统，与现有的分布式文件系统有许多相似之处，但也存在明显的区别。HDFS具有非常好的容错能力，旨在部署在低成本硬件上。HDFS支持对应用程序数据进行高吞吐量访问，并且适用于具有海量数据集的读写。HDFS是Hadoop的核心组件之一，用于存储数据。

### **HDFS简介及架构**

HDFS是以分布式进行存储的文件系统，主要负责集群数据的存储与读取。分布式系统可以划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进行协作，以实现最终的整体功能。利用多个节点共同协作完成一项或多项具体业务功能的系统即为分布式系统。

HDFS作为一个分布式文件系统，其分布式主要体现在如下3个方面。

**1）HDFS并不是一个单机文件系统，而是分布在多个集群节点上的文件系统。**节点之间通过网络通信进行协作，提供多个节点的文件信息，使每个用户均可以看到文件系统的文件，使多台机器上的多用户可以分享文件和存储空间。

**2）当存储文件时，文件的数据将分布在多个节点上。**数据存储不是按一个文件存储，而是将一个文件分成一个或多个数据块进行存储。数据块在存储时并不是都存储在一个节点上，而是被分别存储在各个节点中，并且数据块会在其他节点存储副本。

**3）数据从多个节点读取。**读取一个文件时，从多个节点中找到该文件的数据块，分别读取所有数据块，直至最后一个数据块读取完毕。

HDFS是一个主/从（Master/Slave）体系架构的分布式文件系统。HDFS支持传统的层次型文件组织结构，使得用户或应用程序可以创建目录，再将文件保存至目录中。文件系统命名空间的层次结构和大多数现有的文件系统类似，可以通过文件路径对文件执行创建、读取、更新和删除操作。HDFS的基本架构如图2所示。



![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/v2-a4355f6cb480af7c2f709e3c745f7dcc_1440w.jpg)

HDFS文件系统主要包含一个NameNode、一个Secondary NameNode和多个DataNode。

#### **（1）NameNode**

NameNode用于存储元数据以及处理客户端发出的请求。元数据不是具体的文件内容，它包含3类重要信息。第1类信息是文件和目录自身的属性信息，如文件名、目录名、父目录信息、文件大小、创建时间、修改时间等；第2类信息是记录文件内容存储的相关信息，如文件分块情况、副本个数、每个副本所在的DataNode信息等；第3类信息是用于记录HDFS中所有DataNode的信息，用于DataNode管理。

在NameNode中存放元信息的文件是fsimage文件。在系统运行期间，所有对元数据的操作均保存在内存中，并被持久化到另一个文件edits中。当NameNode启动时，fsimage文件将被加载至内存，再对内存里的数据执行edits文件所记录的操作，以确保内存所保留的数据处于最新的状态。

#### **（2）Secondary NameNode**

Secondary NameNode用于备份NameNode的数据，周期性地将edits文件合并到fsimage文件并在本地备份，然后将新的fsimage文件存储至NameNode，覆盖原有的fsimage文件，删除edits文件，并创建一个新的edits文件继续存储文件当前的修改状态。

#### **（3）DataNode**

DataNode是真正存储数据的地方。在DataNode中，文件以数据块的形式进行存储。Hadoop 3.x默认128 MB为一个数据块，如果存储一个大小为129 MB的文件，那么文件将被分为两个数据块进行存储。当文件上传至HDFS端时，HDFS会将文件按128MB的数据块大小进行切割，将每个数据块存储至不同的或相同的DataNode并备份副本，一般默认备份3个副本。NameNode负责记录文件的分块信息，以确保在读取该文件时可以找到并整合所有数据块。

### **HDFS的特点**

随着数据量越来越多，传统的单机式文件存储系统已经不能满足日益增长的数据存储需求，分布式文件存储系统—HDFS应运而生。作为分布式文件系统，HDFS能够解决海量数据的存储问题，其优点列举如下。

**1）高容错性。**HDFS上传的数据会自动保存多个副本，通过增加副本的数量增加HDFS的容错性。如果某一个副本丢失，那么HDFS将复制其他节点上的副本。

**2）适合大规模数据的处理。**HDFS能够处理GB、TB甚至PB级别的数据，数量级规模可达百万，数量非常大。

**3）流式数据访问。**HDFS以流式数据访问模式存储超大文件，有着“一次写入，多次读取”的特点，且文件一旦写入，不能修改，只能增加，以保证数据的一致性。

当然HDFS也不是完美的，同样存在局限性，如不适合低延迟数据访问，无法高效存储大量小文件、不支持多用户写入及任意修改文件。

## **Hadoop计算引擎—`MapReduce`**

MapReduce是一个分布式运算程序的编程框架，是基于Hadoop的数据分析应用的核心框架。MapReduce的核心功能是将用户编写的业务逻辑代码和自带的组件整合成一个完整的分布式运算程序，并行运行在Hadoop集群上。认识MapReduce分布式计算框架，并了解MapReduce的执行流程，有利于后续的MapReduce编程学习。

MapReduce是Hadoop的核心计算框架，是用于大规模数据集（大于1TB）并行运算的编程模型，主要包括**Map（映射）**和**Reduce（规约）**两个阶段。

1）当启动一个MapReduce任务时，Map端将会读取HDFS上的数据，将数据映射成所需要的键值对类型并传至Reduce端。

2）Reduce端接收Map端键值对类型的中间数据，并根据不同键进行分组，对每一组键相同的数据进行处理，得到新的键值对并输出至HDFS。

MapReduce作业执行流程如图所示。

![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/v2-c594bbad850ec9f6fce189906f664553_1440w.jpg)

一个完整的MapReduce过程涉及数据的输入与分片、Map阶段数据处理、Shuffle&Sort阶段数据整合、Reduce阶段数据处理、数据输出等操作。

**1）数据的输入与分片。**MapReduce过程中的数据是从HDFS分布式文件系统中读取的。文件上传至HDFS时，一般按照128 MB分成若干个数据块，所以在运行MapReduce程序时，每个数据块均会对应一个Map任务。也可以通过重新设置文件分片大小调整Map的个数，在运行MapReduce程序时系统会根据所设置的分片大小对文件重新分片（Split）。

**2）Map阶段数据处理。**一个程序有一个或多个Map任务，具体由默认存储或分片个数决定。在Map阶段，数据将以键值对的形式被读入，键的值一般为每行首字符与文件最初始位置的偏移量，即中间所隔字符个数，值为该行的数据记录。根据具体的需求对键值对进行处理，映射成新的键值对并传输至Reduce端。

**3）Shuffle&Sort阶段数据整合。**此阶段是指从Map端输出开始，传输至Reduce端之前的过程。该过程会对同一个Map中输出的键相同的数据先进行整合，减少传输的数据量，并在整合后将数据按照键进行排序。

**4）Reduce阶段数据处理。**Reduce任务可以有一个或多个，具体由Map阶段设置的数据分区确定，一个分区数据将被一个Reduce处理。针对每一个Reduce任务，Reduce会接收到不同Map任务传来的数据，并且每个Map传来的数据都是有序的。一个Reduce任务中的每一次处理均是针对所有键相同的数据，对数据进行规约，形成新的键值对。

**5）数据输出。**Reduce阶段处理完数据后即可将数据文件输出至HDFS，输出的文件个数和Reduce的个数一致。如果只有一个Reduce，那么输出只有一个数据文件，默认命名为“part-r-00000”。

## **Hadoop资源管理器—`YARN`**

YARN是Hadoop的资源管理器，可以提高资源在集群的利用率，加快执行速率。早期的Hadoop 1.0版本的任务执行效率低下，Hadoop 2.x版本开始引入了YARN框架。YARN框架为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。

Hadoop YARN提供了一个更加通用的资源管理和分布式应用框架。该框架使得用户可以根据自己的需求实现定制化的数据处理应用，既可以支持MapReduce计算，也可以很方便地管理如Hive、HBase、Pig、Spark/Shark等组件的应用程序。YARN的架构设计使得各类型的应用程序可以运行在Hadoop上，并通过YARN从系统层面进行统一管理。拥有了YARN框架，各种应用可以互不干扰地运行在同一个Hadoop系统中，以共享整个集群资源。

YARN框架总体上仍然是主/从结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。用户提交一个应用程序时，需要提供一个用于跟踪和管理这个程序的ApplicationMaster，ApplicationMaster负责向ResourceManager申请资源，并要求NodeManger启动可以占用一定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，所以它们之间不会相互影响。

YARN的基本组成框架如图所示。



![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/v2-617e6da872567efa43770454b347f0b2_1440w.jpg)

YARN主要由ResourceManager、Node-Manager、ApplicationMaster和Client App-lication这4个部分构成，具体说明如下。

**1）ResourceManager（RM）。**一个全局的资源管理器，负责整个系统的资源管理和分配。ResourceManager主要由两个组件构成，即调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。

调度器负责将系统中的资源分配给各个正在运行的应用程序，不从事任何与具体应用程序相关的工作，如监控或跟踪应用的执行状态等，也不负责重新启动因应用执行失败或硬件故障而产生的失败任务。

应用程序管理器负责处理客户端提交的Job以及协商第一个Container（包装资源的对象）以供ApplicationMaster运行，并且在ApplicationMaster失败时将其重新启动。其中，Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。当ApplicationMaster向RM申请资源时，RM为ApplicationMaster返回的资源就是使用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。

**2）NodeManager（NM）。**每个节点上的资源和任务管理器。一方面，NM会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，NM会接收并处理来自ApplicationMaster的Container启动或停止等各种请求。

**3）ApplicationMaster（AM）。**在用户提交每个应用程序时，系统会生成一个ApplicationMaster并保存到提交的应用程序里。ApplicationMaster的主要功能如下。

- 与ResourceManager调度器协商以获取资源（用Container表示）。

- 对得到的任务进行进一步分配。

- 与NodeManager通信以启动或停止任务。

- 监控所有任务运行状态，在任务运行失败时重新为任务申请资源并重启任务。

  

**4）Client Application。**Client Application是客户端提交的应用程序。客户端会将应用程序提交到RM，然后RM将创建一个Application上下文件对象，再设置AM必需的资源请求信息，最后提交至RM。

## Hadoop能干什么

`大数据存储`：分布式存储

`日志处理`：擅长日志分析

`ETL`:数据抽取到oracle、mysql、DB2、mongdb及主流数据库

`机器学习`: 比如Apache Mahout项目

`搜索引擎`:Hadoop + lucene实现

`数据挖掘`：目前比较流行的广告推荐，个性化广告推荐

Hadoop是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。

> hadoop擅长日志分析，facebook就用[Hive](http://lib.csdn.net/base/hive)来进行日志分析，2009年时facebook就有非编程人员的30%的人使用HiveQL进行数据分析；淘宝搜索中  的 自定义筛选也使用的Hive；利用Pig还可以做高级的数据处理，包括Twitter、LinkedIn 上用于发现您可能认识的人，可以实现类似Amazon.com的协同过滤的推荐效果。淘宝的商品推荐也是！在Yahoo！的40%的Hadoop作业是用pig运行的，包括垃圾邮件的识别和过滤，还有用户特征建模。（2012年8月25新更新，天猫的推荐系统是hive，少量尝试mahout！）
>
> **下面举例说明：**
>
> ​    设想一下这样的应用场景. 我有一个100M 的[数据库](http://lib.csdn.net/base/mysql)备份的sql 文件.我现在想在不导入到数据库的情况下直接用grep操作通过正则过滤出我想要的内容。例如：某个表中 含有相同关键字的记录那么有几种方式,一种是直接用[Linux](http://lib.csdn.net/base/linux)的命令 grep 还有一种就是通过编程来读取文件,然后对每行数据进行正则匹配得到结果好了 现在是100M 的数据库备份.上述两种方法都可以轻松应对.
> 那么如果是1G , 1T 甚至 1PB 的数据呢 ,上面2种方法还能行得通吗？ 答案是不能.毕竟单台服务器的性能总有其上限.那么对于这种 超[大数据](http://lib.csdn.net/base/hadoop)文件怎么得到我们想要的结果呢？
> 有种方法 就是分布式计算, 分布式计算的核心就在于 利用分布式[算法](http://lib.csdn.net/base/datastructure) 把运行在单台机器上的程序扩展到多台机器上并行运行.从而使数据处理能力成倍增加.但是这种分布式计算一般对编程人员要求很高,而且对服务器也有要求.导致了成本变得非常高.
> Haddop 就是为了解决这个问题诞生的.Haddop 可以很轻易的把 很多linux的廉价pc 组成 分布式结点,然后编程人员也不需要知道分布式算法之类,只需要根据mapreduce的规则定义好接口方法,剩下的就交给Haddop. 它会自动把相关的计算分布到各个结点上去,然后得出结果.
> 例如上述的例子 ： Hadoop 要做的事 首先把 1PB的数据文件导入到 HDFS中, 然后编程人员定义好 map和reduce, 也就是把文件的行定义为key,每行的内容定义为value , 然后进行正则匹配,匹配成功则把结果 通过reduce聚合起来返回.Hadoop 就会把这个程序分布到N 个结点去并行的操作.
> 那么原本可能需要计算好几天,在有了足够多的结点之后就可以把时间缩小到几小时之内.
>
>
> 这也就是所谓的 `大数据 云计算`了.如果还是不懂的话再举个简单的例子
> 比如 1亿个 1 相加 得出计算结果, 我们很轻易知道结果是 1亿.但是计算机不知道.那么单台计算机处理的方式做一个一亿次的循环每次结果+1
> 那么分布式的处理方式则变成 我用 1万台 计算机,每个计算机只需要计算 1万个 1 相加 然后再有一台计算机把 1万台计算机得到的结果再相加
> 从而得到最后的结果.
> 理论上讲, 计算速度就提高了 1万倍. 当然上面可能是一个不恰当的例子.但所谓分布式,大数据,云计算 大抵也就是这么回事了.

#### 实际应用：

（1）Flume+Logstash+Kafka+Spark Streaming进行实时日志处理分析

![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/550dfc9b8efda80a3a2d29e267349326.png)

（2）酷狗音乐的大数据平台

![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/10f957ddb8910ad4be465b896d94173e.png)

在大数据背景下，Apache Hadoop作为一种分布式存储和计算框架，已经被广泛应用到各行各业，业界对于Hadoop这一开源分布式技术的应用也在不断地拓展中。了解Hadoop的应用场景，从而可以更深刻地了解Hadoop在实际生活中的应用。

**1）在线旅游。**目前全球范围内大多数在线旅游网站都使用了Cloudera公司提供的Hadoop发行版，Expedia作为全球最大的在线旅游公司也在使用Hadoop。在国内目前比较受欢迎的一些旅游网站如携程、去哪儿网等也采用了大数据技术对数据进行存储和计算。

**2）移动数据。**中国移动于2010年5月正式推出大云BigCloud 1.0，集群节点达到了1024个。华为对Hadoop的HA方案及HBase领域也有深入研究，并已经向业界推出了自己的基于Hadoop的大数据解决方案。

**3）电子商务。**阿里巴巴的Hadoop集群拥有150个用户组、4500个集群用户，为淘宝、天猫、一淘、聚划算、CBU、支付宝提供底层的基础计算和存储服务。

**4）诈骗检测。**一般金融服务或政府机构会使用Hadoop存储所有的客户交易数据，包括一些非结构化的数据，以帮助机构发现客户的异常活动，预防欺诈行为。例如国内支付宝、微信钱包这类庞大的互联网支付平台，对诈骗、黑客、病毒的防护都十分重视，均使用大数据技术进行诈骗检测，以保障线上资金的安全。

**5）IT安全。**除企业IT基础机构的管理外，Hadoop还可以用于处理机器生成的数据以便识别出来自恶意软件或网络中的攻击。国内奇虎360安全软件在应用方面也使用Hadoop的HBase组件进行数据存储，缩短了异常恢复的时间。

**6）医疗保健。**医疗行业也可以使用Hadoop，如IBM Watson技术平台使用Hadoop集群作为语义分析等高级分析技术的基础。医疗机构可以利用语义分析为患者提供医护人员，并协助医生更好地为患者进行诊断。

**7）搜索引擎。**我们在使用搜索引擎的过程中会产生大规模的数据，此时，使用Hadoop进行海量数据挖掘可以提高数据处理的效率。国外的雅虎已将Hadoop应用到搜索引擎中，国内的百度和阿里巴巴也将Hadoop应用到搜索引擎、推荐、数据分析等多个领域。

**8）社交平台。**目前网络社交已经成为人们日常生活的一部分，网络社交平台每天产生的数据量十分庞大。腾讯和脸书作为国内外的大型社交平台，在数据库存储方面均利用了Hadoop生态系统中的Hive组件进行数据存储和处理。

## **Hadoop生态系统**

Hadoop经过多年的发展，已经形成了一个相当成熟的生态系统。现代生活节奏快速，各行各业无时无刻产生着大量的数据，Hadoop发挥着重要的作用。因为各行各业的需求不同，很多时候需要在Hadoop的基础上进行一些改进和优化，也因此产生了许多围绕Hadoop衍生的工具，逐渐地演变成一个庞大的Hadoop生态系统，如图所示。

![img](img/1_hadoop%E4%BB%8B%E7%BB%8D/v2-4fa63027d2540dbc911d619d858dcfa1_1440w.jpg)

Hadoop生态系统中常用的组件列举如下，不同的组件分别提供特定的服务。

**1）Hive。**Hive是建立在Hadoop基础上的数据仓库基础框架，提供了一系列工具，可存储、查询和分析存储在Hadoop中的大规模数据。Hive定义了一种类SQL语言为HQL，该语言编写的查询语句在Hive的底层将转换为复杂的MapReduce程序，运行在Hadoop大数据平台上。

**2）ZooKeeper。**ZooKeeper主要用于保证集群各项功能的正常进行，并能够在功能出现异常时及时通知集群进行处理，保持数据一致性。ZooKeeper是对整个集群进行监控，可解决分布式环境下的数据管理问题。

**3）HBase。**HBase是一个针对非结构化数据的可伸缩、高可靠、高性能、分布式和面向列的动态模式数据库。HBase提供了对大规模数据的随机、实时读写访问。同时，HBase中保存的数据可以使用MapReduce进行处理。HBase将数据存储和并行计算很好地结合在一起。

**4）Spark。**Spark是一种快速、通用、可扩展的大数据处理引擎，继承了MapReduce分布式计算的优点并改进了MapReduce明显的缺点。Spark的中间输出结果可以保存在内存中，因此能更好地适用于数据挖掘与机器学习中迭代次数较多的算法。

**5）Flume。**Flume是Cloudera提供的一个高可用的、高可靠的、分布式的海量日志采集、聚合和传输系统，适用于日志文件的采集。

**6）Kafka。**Kafka是一个分布式的基于发布/订阅模式的消息队列，主要应用于大数据实时处理领域。Kafka是一个事件流平台，能够连接其他数据源进行持续的数据导入或导出，并且可以根据需求持久可靠地存储数据。